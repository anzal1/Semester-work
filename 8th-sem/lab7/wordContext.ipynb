{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-occurrence matrix M:\n",
      "[[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 2. 0. 2. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 2. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 0. 0. 0. 1. 2. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "\n",
      "Word to index mapping:\n",
      "{'a': 0, 'am': 1, 'artificial': 2, 'i': 3, 'intelligence': 4, 'is': 5, 'language': 6, 'natural': 7, 'of': 8, 'processing': 9, 'studying': 10, 'subset': 11}\n",
      "Words similar to a: ['a', 'of', 'processing', 'subset', 'studying']\n",
      "\n",
      "\n",
      "Words similar to am: ['am', 'natural', 'subset', 'studying', 'processing']\n",
      "\n",
      "\n",
      "Words similar to artificial: ['artificial', 'subset', 'studying', 'processing', 'of']\n",
      "\n",
      "\n",
      "Words similar to i: ['i', 'studying', 'subset', 'processing', 'of']\n",
      "\n",
      "\n",
      "Words similar to intelligence: ['intelligence', 'of', 'subset', 'studying', 'processing']\n",
      "\n",
      "\n",
      "Words similar to is: ['is', 'subset', 'language', 'studying', 'processing']\n",
      "\n",
      "\n",
      "Words similar to language: ['language', 'studying', 'is', 'subset', 'processing']\n",
      "\n",
      "\n",
      "Words similar to natural: ['natural', 'processing', 'am', 'subset', 'studying']\n",
      "\n",
      "\n",
      "Words similar to of: ['of', 'intelligence', 'a', 'subset', 'studying']\n",
      "\n",
      "\n",
      "Words similar to processing: ['processing', 'natural', 'a', 'subset', 'studying']\n",
      "\n",
      "\n",
      "Words similar to studying: ['studying', 'i', 'language', 'subset', 'processing']\n",
      "\n",
      "\n",
      "Words similar to subset: ['subset', 'is', 'artificial', 'studying', 'processing']\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import string\n",
    "import re\n",
    "\n",
    "\n",
    "def distinct_words(corpus):\n",
    "    \"\"\" Determine a list of distinct words for the corpus.\n",
    "\n",
    "        Params:\n",
    "            corpus (list of list of strings): corpus of documents\n",
    "        Return:\n",
    "            words (list of strings): list of distinct words across the corpus, sorted (using python 'sorted' function)\n",
    "            num_words (integer): number of distinct words across the corpus\n",
    "    \"\"\"\n",
    "    words = []\n",
    "    num_words = -1\n",
    "\n",
    "    words = [word for sentence in corpus for word in sentence]\n",
    "    words = sorted(set(words))\n",
    "    num_words = len(words)\n",
    "\n",
    "    return words, num_words\n",
    "\n",
    "\n",
    "def compute_co_occurrence_matrix(corpus, window_size=4):\n",
    "    \"\"\" Compute co-occurrence matrix for the given corpus and window_size (default of 4).\n",
    "\n",
    "        Note: Each word in a document should be at the center of a window. Words near edges will have a smaller\n",
    "              number of co-occurring words.\n",
    "\n",
    "              For example, if we take the document \"START All that glitters is not gold END\" with window size of 4,\n",
    "              \"All\" will co-occur with \"START\", \"that\", \"glitters\", \"is\", and \"not\".\n",
    "\n",
    "        Params:\n",
    "            corpus (list of list of strings): corpus of documents\n",
    "            window_size (int): size of context window\n",
    "        Return:\n",
    "            M (numpy matrix of shape (number of corpus words, number of corpus words)): \n",
    "                Co-occurence matrix of word counts. \n",
    "                The ordering of the words in the rows/columns should be the same as the ordering of the words given by the distinct_words function.\n",
    "            word2Ind (dict): dictionary that maps word to index (i.e. row/column number) for matrix M.\n",
    "    \"\"\"\n",
    "    words, num_words = distinct_words(corpus)\n",
    "    M = None\n",
    "    word2Ind = {}\n",
    "\n",
    "    # import numpy as np\n",
    "    M = np.zeros((len(words), len(words)))\n",
    "    words = list(words)\n",
    "    for center_word in words:\n",
    "        index = words.index(center_word)\n",
    "        word2Ind[center_word] = index\n",
    "        for sentence in corpus:\n",
    "            for index_of_center_word, word in enumerate(sentence):\n",
    "                if center_word == word:\n",
    "                    for i in range(window_size):\n",
    "                        if index_of_center_word-i-1 >= 0:\n",
    "                            l_n = sentence[index_of_center_word-i-1]\n",
    "                            M[index, words.index(l_n)] += 1\n",
    "                        if index_of_center_word + i+1 < len(sentence):\n",
    "                            r_n = sentence[index_of_center_word+i+1]\n",
    "                            M[index, words.index(r_n)] += 1\n",
    "\n",
    "    return M, word2Ind\n",
    "\n",
    "\n",
    "# Define toy corpus and get co-occurrence matrix\n",
    "corpus = [\"I am studying Natural Language Processing\",\n",
    "          \"Natural Language Processing is a subset of Artificial Intelligence\"]\n",
    "\n",
    "\n",
    "# add START and END to each sentence\n",
    "\n",
    "corpus = [re.findall(r'\\b\\w+\\b', sentence.lower()) for sentence in corpus]\n",
    "\n",
    "\n",
    "M, word2Ind = compute_co_occurrence_matrix(corpus, window_size=1)\n",
    "\n",
    "print(\"Co-occurrence matrix M:\")\n",
    "\n",
    "print(M)\n",
    "print(\"\\nWord to index mapping:\")\n",
    "\n",
    "print(word2Ind)\n",
    "\n",
    "\n",
    "def find_similar_words(word, M, word2Ind, k=5):\n",
    "    \"\"\" Find top k most similar words to a given word.\n",
    "\n",
    "        Params:\n",
    "            word (string): word to compare similarity\n",
    "            M (numpy matrix of shape (number of corpus words, number of corpus words)): co-occurrence matrix of word counts\n",
    "            word2Ind (dict): dictionary that maps word to index (i.e. row/column number) for matrix M\n",
    "            k (int): number of top similar words to return\n",
    "        Return:\n",
    "            similar_words (list of strings): list of top k most similar words\n",
    "    \"\"\"\n",
    "    similar_words = []\n",
    "\n",
    "    word_index = word2Ind[word]\n",
    "    word_vector = M[word_index]\n",
    "    similarity = []\n",
    "    for i in range(len(M)):\n",
    "        similarity.append((np.dot(\n",
    "            M[i], word_vector) / (np.linalg.norm(M[i]) * np.linalg.norm(word_vector)), i))\n",
    "    similarity = sorted(similarity, reverse=True)\n",
    "    for i in range(k):\n",
    "        similar_words.append(list(word2Ind.keys())[list(\n",
    "            word2Ind.values()).index(similarity[i][1])])\n",
    "\n",
    "    return similar_words\n",
    "\n",
    "\n",
    "# Test the function\n",
    "\n",
    "#  find similarity between all pairs of words from the toy corpus\n",
    "\n",
    "for word in word2Ind.keys():\n",
    "    print(f\"Words similar to {word}: {find_similar_words(word, M, word2Ind)}\")\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
